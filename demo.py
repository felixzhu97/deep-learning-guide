#!/usr/bin/env python3
"""
æ·±åº¦å­¦ä¹ å…¥é—¨é¡¹ç›®æ¼”ç¤ºè„šæœ¬
é¡¹ç›®ä¸»è¦å…¥å£ç‚¹ï¼Œæä¾›å„ç§æ¼”ç¤ºå’Œæµ‹è¯•åŠŸèƒ½
"""

import os
import sys
import time
import numpy as np

# ç¡®ä¿é¡¹ç›®æ ¹ç›®å½•åœ¨Pythonè·¯å¾„ä¸­
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

from data.mnist_loader import load_mnist
from data.preprocessor import preprocess_data
from models.pixel_similarity import PixelSimilarityClassifier
from models.neural_network import NeuralNetwork
from utils.visualization import plot_model_comparison


def print_header():
    """æ‰“å°é¡¹ç›®å¤´éƒ¨ä¿¡æ¯"""
    print("\n" + "="*70)
    print("ğŸš€ æ·±åº¦å­¦ä¹ å…¥é—¨é¡¹ç›®æ¼”ç¤º")
    print("ğŸ“š åŸºäºã€Šæ·±åº¦å­¦ä¹ å…¥é—¨ã€‹ï¼ˆæ–‹è—¤åº·æ¯…è‘—ï¼‰")
    print("ğŸ¯ MNISTæ‰‹å†™æ•°å­—è¯†åˆ« - ä»åŸºç¡€åˆ°æ·±åº¦å­¦ä¹ ")
    print("="*70)


def check_dependencies():
    """æ£€æŸ¥é¡¹ç›®ä¾èµ–"""
    print("ğŸ“‹ æ£€æŸ¥é¡¹ç›®ä¾èµ–...")
    
    required_packages = [
        'numpy', 'matplotlib', 'scikit-learn', 
        'requests', 'tqdm', 'Pillow'
    ]
    
    missing_packages = []
    
    for package in required_packages:
        try:
            __import__(package)
            print(f"âœ… {package}")
        except ImportError:
            missing_packages.append(package)
            print(f"âŒ {package} - ç¼ºå¤±")
    
    if missing_packages:
        print(f"\nâš ï¸  ç¼ºå°‘ä»¥ä¸‹ä¾èµ–åŒ…: {', '.join(missing_packages)}")
        print("è¯·è¿è¡Œ: pip install -r requirements.txt")
        return False
    
    print("âœ… æ‰€æœ‰ä¾èµ–éƒ½å·²å®‰è£…")
    return True


def quick_demo():
    """å¿«é€Ÿæ¼”ç¤º"""
    print("\nğŸ¬ å¿«é€Ÿæ¼”ç¤ºå¼€å§‹...")
    print("ä½¿ç”¨å°‘é‡æ•°æ®å±•ç¤ºå„ç§æ–¹æ³•çš„æ•ˆæœ")
    
    # åŠ è½½æ•°æ®
    print("\nğŸ“¥ åŠ è½½MNISTæ•°æ®...")
    train_images, train_labels, test_images, test_labels = load_mnist()
    
    # ä½¿ç”¨å°‘é‡æ•°æ®è¿›è¡Œæ¼”ç¤º
    print("ğŸ”§ å‡†å¤‡æ¼”ç¤ºæ•°æ®...")
    train_sample = 1000
    test_sample = 200
    
    X_train = train_images[:train_sample]
    y_train = train_labels[:train_sample]
    X_test = test_images[:test_sample]
    y_test = test_labels[:test_sample]
    
    print(f"è®­ç»ƒæ ·æœ¬: {train_sample}, æµ‹è¯•æ ·æœ¬: {test_sample}")
    
    results = {}
    
    # 1. åƒç´ ç›¸ä¼¼æ€§æ–¹æ³•
    print("\nğŸ” æµ‹è¯•åƒç´ ç›¸ä¼¼æ€§æ–¹æ³•...")
    X_train_pixel, y_train_pixel, X_test_pixel, y_test_pixel = preprocess_data(
        X_train, y_train, X_test, y_test, method='pixel_similarity'
    )
    
    pixel_classifier = PixelSimilarityClassifier(similarity_metric='euclidean', k=3)
    pixel_classifier.fit(X_train_pixel, y_train_pixel)
    
    # åªç”¨å°‘é‡æµ‹è¯•æ ·æœ¬ä»¥èŠ‚çœæ—¶é—´
    test_subset = 50
    pixel_results = pixel_classifier.evaluate(X_test_pixel[:test_subset], y_test_pixel[:test_subset])
    results['åƒç´ ç›¸ä¼¼æ€§'] = pixel_results['accuracy']
    
    print(f"âœ… åƒç´ ç›¸ä¼¼æ€§å‡†ç¡®ç‡: {pixel_results['accuracy']:.3f}")
    
    # 2. ç®€å•ç¥ç»ç½‘ç»œ
    print("\nğŸ§  æµ‹è¯•ç®€å•ç¥ç»ç½‘ç»œ...")
    X_train_nn, y_train_nn, X_test_nn, y_test_nn = preprocess_data(
        X_train, y_train, X_test, y_test, method='neural_network'
    )
    
    nn = NeuralNetwork(
        input_size=784,
        hidden_sizes=[64, 32],
        output_size=10,
        activation='relu'
    )
    
    nn.fit(X_train_nn, y_train_nn, epochs=10, batch_size=32, 
           learning_rate=0.01, verbose=False)
    
    nn_results = nn.evaluate(X_test_nn, y_test_nn)
    results['ç®€å•ç¥ç»ç½‘ç»œ'] = nn_results['accuracy']
    
    print(f"âœ… ç¥ç»ç½‘ç»œå‡†ç¡®ç‡: {nn_results['accuracy']:.3f}")
    
    # ç»“æœå¯¹æ¯”
    print("\nğŸ“Š ç»“æœå¯¹æ¯”:")
    print("-" * 30)
    for method, accuracy in results.items():
        print(f"{method:12s}: {accuracy:.3f}")
    
    # å¯è§†åŒ–å¯¹æ¯”
    print("\nğŸ“ˆ ç”Ÿæˆå¯¹æ¯”å›¾è¡¨...")
    plot_model_comparison(
        results, 
        metric='å‡†ç¡®ç‡',
        title="MNISTåˆ†ç±»æ–¹æ³•å¯¹æ¯”ï¼ˆå¿«é€Ÿæ¼”ç¤ºï¼‰",
        save_path="quick_demo_comparison.png"
    )
    
    print("\nğŸ‰ å¿«é€Ÿæ¼”ç¤ºå®Œæˆï¼")
    return results


def comprehensive_demo():
    """å…¨é¢æ¼”ç¤º"""
    print("\nğŸ¯ å…¨é¢æ¼”ç¤ºå¼€å§‹...")
    print("ä½¿ç”¨æ›´å¤šæ•°æ®å’Œå®Œæ•´åŠŸèƒ½è¿›è¡Œæ¼”ç¤º")
    
    # è¯¢é—®ç”¨æˆ·ç¡®è®¤
    confirm = input("å…¨é¢æ¼”ç¤ºéœ€è¦è¾ƒé•¿æ—¶é—´ï¼ˆ10-30åˆ†é’Ÿï¼‰ï¼Œæ˜¯å¦ç»§ç»­ï¼Ÿ(y/n): ").strip().lower()
    if confirm != 'y':
        print("å·²å–æ¶ˆå…¨é¢æ¼”ç¤º")
        return
    
    # è¿è¡Œå„ä¸ªæ¨¡å—çš„å®Œæ•´æ¼”ç¤º
    print("\nğŸ” è¿è¡Œåƒç´ ç›¸ä¼¼æ€§æ–¹æ³•å®Œæ•´æ¼”ç¤º...")
    os.system("python examples/train_pixel_similarity.py")
    
    print("\nğŸ§  è¿è¡Œç¥ç»ç½‘ç»œå®Œæ•´æ¼”ç¤º...")
    os.system("python examples/train_neural_network.py")
    
    print("\nğŸ‰ å…¨é¢æ¼”ç¤ºå®Œæˆï¼")


def data_exploration():
    """æ•°æ®æ¢ç´¢"""
    print("\nğŸ” MNISTæ•°æ®é›†æ¢ç´¢...")
    
    # åŠ è½½æ•°æ®
    train_images, train_labels, test_images, test_labels = load_mnist()
    
    print(f"ğŸ“Š æ•°æ®é›†ç»Ÿè®¡:")
    print(f"   è®­ç»ƒé›†: {train_images.shape[0]:,} ä¸ªæ ·æœ¬")
    print(f"   æµ‹è¯•é›†: {test_images.shape[0]:,} ä¸ªæ ·æœ¬")
    print(f"   å›¾åƒå°ºå¯¸: {train_images.shape[1]}Ã—{train_images.shape[2]}")
    print(f"   åƒç´ å€¼èŒƒå›´: [{train_images.min()}, {train_images.max()}]")
    print(f"   æ ‡ç­¾èŒƒå›´: [{train_labels.min()}, {train_labels.max()}]")
    
    # å„ç±»åˆ«æ ·æœ¬æ•°é‡
    print(f"\nğŸ“ˆ å„ç±»åˆ«æ ·æœ¬æ•°é‡:")
    for i in range(10):
        count = np.sum(train_labels == i)
        print(f"   æ•°å­— {i}: {count:,} ä¸ªæ ·æœ¬")
    
    # ç”Ÿæˆä¸€äº›æ ·æœ¬å›¾åƒ
    from utils.visualization import visualize_mnist_images
    
    print("\nğŸ–¼ï¸  ç”Ÿæˆæ ·æœ¬å›¾åƒ...")
    sample_indices = np.random.choice(len(train_images), 25, replace=False)
    sample_images = train_images[sample_indices]
    sample_labels = train_labels[sample_indices]
    
    visualize_mnist_images(
        sample_images, sample_labels,
        title="MNISTæ•°æ®é›†æ ·æœ¬",
        save_path="mnist_samples.png"
    )
    
    print("âœ… æ•°æ®æ¢ç´¢å®Œæˆï¼æ ·æœ¬å›¾åƒå·²ä¿å­˜ä¸º mnist_samples.png")


def project_info():
    """é¡¹ç›®ä¿¡æ¯"""
    print("\nğŸ“‹ é¡¹ç›®ä¿¡æ¯:")
    print("-" * 50)
    
    # ç»Ÿè®¡é¡¹ç›®æ–‡ä»¶
    python_files = []
    for root, dirs, files in os.walk('.'):
        for file in files:
            if file.endswith('.py'):
                python_files.append(os.path.join(root, file))
    
    print(f"ğŸ Pythonæ–‡ä»¶æ•°é‡: {len(python_files)}")
    print(f"ğŸ“ é¡¹ç›®ç›®å½•:")
    
    directories = ['data', 'models', 'utils', 'examples']
    for directory in directories:
        if os.path.exists(directory):
            files = [f for f in os.listdir(directory) if f.endswith('.py')]
            print(f"   {directory}/: {len(files)} ä¸ªæ–‡ä»¶")
    
    print(f"\nğŸ“š å®ç°çš„åŠŸèƒ½:")
    print(f"   âœ… MNISTæ•°æ®åŠ è½½å’Œé¢„å¤„ç†")
    print(f"   âœ… åƒç´ ç›¸ä¼¼æ€§åˆ†ç±»æ–¹æ³•")
    print(f"   âœ… å¤šå±‚æ„ŸçŸ¥æœºç¥ç»ç½‘ç»œ")
    print(f"   âœ… åå‘ä¼ æ’­ç®—æ³•")
    print(f"   âœ… å¤šç§ä¼˜åŒ–å™¨ï¼ˆSGDã€Adamï¼‰")
    print(f"   âœ… è®­ç»ƒè¿‡ç¨‹å¯è§†åŒ–")
    print(f"   âœ… æ€§èƒ½è¯„ä¼°å’Œå¯¹æ¯”")
    
    print(f"\nğŸ¯ å­¦ä¹ ç›®æ ‡:")
    print(f"   ğŸ“– ç†è§£æ·±åº¦å­¦ä¹ åŸºç¡€æ¦‚å¿µ")
    print(f"   ğŸ”§ æŒæ¡ä»é›¶å®ç°ç¥ç»ç½‘ç»œ")
    print(f"   ğŸ“Š å­¦ä¼šè¯„ä¼°å’Œä¼˜åŒ–æ¨¡å‹")
    print(f"   ğŸ¨ ä½“éªŒæ¸è¿›å¼å­¦ä¹ è¿‡ç¨‹")


def main():
    """ä¸»å‡½æ•°"""
    print_header()
    
    # æ£€æŸ¥ä¾èµ–
    if not check_dependencies():
        print("\nâŒ è¯·å…ˆå®‰è£…ä¾èµ–åŒ…")
        return
    
    while True:
        print("\nğŸ® è¯·é€‰æ‹©æ“ä½œ:")
        print("1. ğŸš€ å¿«é€Ÿæ¼”ç¤º (æ¨èï¼Œ5-10åˆ†é’Ÿ)")
        print("2. ğŸ¯ å…¨é¢æ¼”ç¤º (å®Œæ•´åŠŸèƒ½ï¼Œ10-30åˆ†é’Ÿ)")
        print("3. ğŸ” æ•°æ®æ¢ç´¢")
        print("4. ğŸ“‹ é¡¹ç›®ä¿¡æ¯")
        print("5. ğŸ“š æŸ¥çœ‹README")
        print("6. ğŸšª é€€å‡º")
        
        choice = input("\nè¯·è¾“å…¥é€‰æ‹© (1-6): ").strip()
        
        if choice == '1':
            quick_demo()
        elif choice == '2':
            comprehensive_demo()
        elif choice == '3':
            data_exploration()
        elif choice == '4':
            project_info()
        elif choice == '5':
            if os.path.exists('README.md'):
                with open('README.md', 'r', encoding='utf-8') as f:
                    content = f.read()
                print("\nğŸ“– README.md:")
                print("-" * 50)
                print(content)
            else:
                print("âŒ README.md æ–‡ä»¶ä¸å­˜åœ¨")
        elif choice == '6':
            break
        else:
            print("âŒ æ— æ•ˆé€‰æ‹©ï¼Œè¯·é‡æ–°è¾“å…¥")
    
    print("\nğŸ‘‹ æ„Ÿè°¢ä½¿ç”¨æ·±åº¦å­¦ä¹ å…¥é—¨é¡¹ç›®ï¼")
    print("ğŸ“§ å¦‚æœ‰é—®é¢˜ï¼Œè¯·æŸ¥çœ‹README.mdæˆ–é¡¹ç›®æ–‡æ¡£")
    print("ğŸŒŸ ç¥æ‚¨æ·±åº¦å­¦ä¹ ä¹‹æ—…æ„‰å¿«ï¼")


if __name__ == "__main__":
    main() 